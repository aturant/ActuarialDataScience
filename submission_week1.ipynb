{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "submission_week1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aturant/ActuarialDataScience/blob/master/submission_week1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWq4q0Gfp1Ha"
      },
      "source": [
        "<div style=\"text-align: center\">\n",
        "  <img alt=\"AIcrowd\" src=\"https://gitlab.aicrowd.com/jyotish/pricing-game-notebook-scripts/raw/master/pricing-game-banner.png\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIBNi6PiHFfD"
      },
      "source": [
        "# How to use this notebook üìù\n",
        "\n",
        "1. **Copy the notebook**. This is a shared template and any edits you make here will not be saved. _You should copy it into your own drive folder._ For this, click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You can edit your copy however you like.\n",
        "2. **Link it to your AICrowd account**. In order to submit your code to AICrowd, you need to provide your account's API key (see [_\"Configure static variables\"_](#static-var) for details).\n",
        "3. **Stick to the function definitions**. The submission to AICrowd will look for the pre-defined function names:\n",
        "  - `fit_model`\n",
        "  - `save_model`\n",
        "  - `load_model`\n",
        "  - `predict_expected_claim`\n",
        "  - `predict_premium`\n",
        "\n",
        "    Anything else you write outside of these functions will not be part of the final submission (including constants and utility functions), so make sure everything is defined within them, except for:\n",
        "4. **Define your preprocessing**. In addition to the functions above, anything in the cell labelled [_\"Define your data preprocessing\"_](#data-preprocessing) will also be imported into your final submission. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uor1bk8ud9Yf"
      },
      "source": [
        "# Your pricing model üïµÔ∏è\n",
        "\n",
        "In this notebook, you can play with the data, and define and train your pricing model. You can then directly submit it to the AICrowd, with some magic code at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOG9aspEPfLo"
      },
      "source": [
        "# Setup the notebook üõ†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc9aD_S9w_Qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f681ad-8070-437c-982a-844c5958293a"
      },
      "source": [
        "!bash <(curl -sL https://gitlab.aicrowd.com/jyotish/pricing-game-notebook-scripts/raw/master/python/setup.sh)\n",
        "from aicrowd_helpers import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚öôÔ∏è Installing AIcrowd utilities...\n",
            "  Running command git clone -q https://gitlab.aicrowd.com/yoogottamk/aicrowd-cli /tmp/pip-req-build-d_2vx725\n",
            "‚úÖ Installed AIcrowd utilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWAkvr2mPqhO"
      },
      "source": [
        "# Configure static variables üìé\n",
        "<a name=\"static-var\"></a>\n",
        "\n",
        "In order to submit using this notebook, you must visit this URL https://aicrowd.com/participants/me and copy your API key. \n",
        "\n",
        "Then you must set the value of `AICROWD_API_KEY` wuth the value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z8nmleFd9Yf"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "class Config:\n",
        "  TRAINING_DATA_PATH = 'training.csv'\n",
        "  MODEL_OUTPUT_PATH = 'model.pkl'\n",
        "  #MODEL_OUTPUT_PATH = 'model'\n",
        "  AICROWD_API_KEY = '0b70146b9714e6c7f3393b86c15e9c4d'  # You can get the key from https://aicrowd.com/participants/me\n",
        "  ADDITIONAL_PACKAGES = [\n",
        "    'numpy',  # you can define versions as well, numpy==0.19.2\n",
        "    'pandas',\n",
        "    'scikit-learn==' + sklearn.__version__,\n",
        "    'h2o',\n",
        "    'xgboost'\n",
        "  ]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByfdjGhDH5Ox",
        "outputId": "8266cf1f-bb95-401e-bfe3-c7a15248cdf2"
      },
      "source": [
        "!pip install h2o"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h2o\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/c5/d63a8bfdbeb4ebfb709c010af3e061d89a363204c437cb5527431f6de3d2/h2o-3.32.0.2.tar.gz (164.6MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164.6MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n",
            "Requirement already satisfied: colorama>=0.3.8 in /usr/local/lib/python3.6/dist-packages (from h2o) (0.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.32.0.2-py2.py3-none-any.whl size=164620456 sha256=4035483d082e1584bd1b7b855472de17d5cd94fb5b735d2f759007cd0dcf917a\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/bd/ea/218fd15724eddf6fa7fc8fab802b6fa592e623d87199679721\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "Successfully installed h2o-3.32.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK8Ki2WUjVoX"
      },
      "source": [
        "# Download dataset files üíæ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgKzpAV0jVFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429f5f6f-1912-44af-96ba-3ec6d2d82c09"
      },
      "source": [
        "%download_aicrowd_dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "üíæ Downloading dataset...\n",
            "Verifying API Key...\n",
            "API Key valid\n",
            "Saved API Key successfully!\n",
            "‚úÖ Downloaded dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wrBpC0qd9Yg"
      },
      "source": [
        "# Packages üóÉ\n",
        "\n",
        "<a name=\"packages\"></a>\n",
        "\n",
        "Import here all the packages you need to define your model. **You will need to include all of these packages in `Config.ADDITIONAL_PACKAGES` for your code to run properly once submitted.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q4C50Fsd9Yg"
      },
      "source": [
        "%%track_imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.linear_model import LinearRegression \n",
        "#import h2o\n",
        "#h2o.init()\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR62QOUGd9Yg"
      },
      "source": [
        "import importlib\n",
        "import global_imports\n",
        "importlib.reload(global_imports)\n",
        "from global_imports import *  # do not change this"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRgsbwWwd9Yg"
      },
      "source": [
        "# Loading the data üì≤"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQQghMU7d9Yg"
      },
      "source": [
        "df = pd.read_csv(Config.TRAINING_DATA_PATH)\n",
        "X_train = df.drop(columns=['claim_amount'])\n",
        "y_train = df['claim_amount']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WArx8uDQd9Yh"
      },
      "source": [
        "## How does the data look like? üîç"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_dyebPyQbSO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "de5515f1-7ea1-4a54-a12d-00206cb0501a"
      },
      "source": [
        "X_train.sample(n=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_policy</th>\n",
              "      <th>year</th>\n",
              "      <th>pol_no_claims_discount</th>\n",
              "      <th>pol_coverage</th>\n",
              "      <th>pol_duration</th>\n",
              "      <th>pol_sit_duration</th>\n",
              "      <th>pol_pay_freq</th>\n",
              "      <th>pol_payd</th>\n",
              "      <th>pol_usage</th>\n",
              "      <th>drv_sex1</th>\n",
              "      <th>drv_age1</th>\n",
              "      <th>drv_age_lic1</th>\n",
              "      <th>drv_drv2</th>\n",
              "      <th>drv_sex2</th>\n",
              "      <th>drv_age2</th>\n",
              "      <th>drv_age_lic2</th>\n",
              "      <th>vh_make_model</th>\n",
              "      <th>vh_age</th>\n",
              "      <th>vh_fuel</th>\n",
              "      <th>vh_type</th>\n",
              "      <th>vh_speed</th>\n",
              "      <th>vh_value</th>\n",
              "      <th>vh_weight</th>\n",
              "      <th>population</th>\n",
              "      <th>town_surface_area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163257</th>\n",
              "      <td>PL085089</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Max</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>Yearly</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Retired</td>\n",
              "      <td>F</td>\n",
              "      <td>90.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nilvygybpajtnxnr</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>Tourism</td>\n",
              "      <td>170.0</td>\n",
              "      <td>11405.0</td>\n",
              "      <td>1197.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>124.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14559</th>\n",
              "      <td>PL024390</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Max</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>Biannual</td>\n",
              "      <td>No</td>\n",
              "      <td>Retired</td>\n",
              "      <td>M</td>\n",
              "      <td>68.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>F</td>\n",
              "      <td>66.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>rwtwnvhjqabvovnz</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Tourism</td>\n",
              "      <td>172.0</td>\n",
              "      <td>29455.0</td>\n",
              "      <td>1910.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>42.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122520</th>\n",
              "      <td>PL052513</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Max</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>Yearly</td>\n",
              "      <td>No</td>\n",
              "      <td>Retired</td>\n",
              "      <td>M</td>\n",
              "      <td>68.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>F</td>\n",
              "      <td>60.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>gsooyxmnwsucrksh</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>Tourism</td>\n",
              "      <td>227.0</td>\n",
              "      <td>66150.0</td>\n",
              "      <td>1484.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>226.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20126</th>\n",
              "      <td>PL033685</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Max</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>Yearly</td>\n",
              "      <td>No</td>\n",
              "      <td>WorkPrivate</td>\n",
              "      <td>M</td>\n",
              "      <td>63.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>F</td>\n",
              "      <td>61.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>iwhqpdfuhrsxyqxe</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>Tourism</td>\n",
              "      <td>150.0</td>\n",
              "      <td>14159.0</td>\n",
              "      <td>1193.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>79.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id_policy  year  ...  population town_surface_area\n",
              "163257  PL085089   3.0  ...       220.0             124.5\n",
              "14559   PL024390   1.0  ...       540.0              42.4\n",
              "122520  PL052513   3.0  ...       300.0             226.2\n",
              "20126   PL033685   1.0  ...       790.0              79.4\n",
              "\n",
              "[4 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoJEQhxMQtq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf86158b-2f9b-4add-e17a-6e709244fef9"
      },
      "source": [
        "y_train.sample(n=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186290    0.0\n",
              "211811    0.0\n",
              "124036    0.0\n",
              "221512    0.0\n",
              "Name: claim_amount, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynDfq7F_d9Yh"
      },
      "source": [
        "# Training the model üöÄ\n",
        "\n",
        "You must first define your first function: `fit_model`. This function takes training data as arguments, and outputs a \"model\" object -- that you define as you wish. For instance, this could be an array of parameter values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpW0yH_Lj2hG"
      },
      "source": [
        "## Define your data preprocessing\n",
        "\n",
        "<a name=\"data-preprocessing\"></a>\n",
        "\n",
        "You can add any class or function in this cell for preprocessing. Just make sure that you use the functions here in the `fit_model`, `predict_expected_claim` and `predict_premium` functions if necessary. *italicised text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buq4-7IIjsUq"
      },
      "source": [
        "%%aicrowd_include\n",
        "# This magical command saves all code in this cell to a utils module.\n",
        "\n",
        "# include your preprocessing functions and classes here.\n",
        "import xgboost as xgb\n",
        "\n",
        "def vh_value_to_weight(x):\n",
        "  if x['vh_weight'] == 0:\n",
        "    return 10^6\n",
        "  else:\n",
        "    return x['vh_value']/x['vh_weight']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtL2L7SgFg0c"
      },
      "source": [
        "import importlib\n",
        "import utils\n",
        "importlib.reload(utils)\n",
        "from utils import *  # do not change this"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAaNQuVxRTUs"
      },
      "source": [
        "## Define the training logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffOanSIvd9Yh"
      },
      "source": [
        "def fit_model(X_raw, y_raw):\n",
        "    \"\"\"Model training function: given training data (X_raw, y_raw), train this pricing model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
        "        Each row is a different contract. This data has not been processed.\n",
        "    y_raw : a Numpy array, with the value of the claims, in the same order as contracts in X_raw.\n",
        "        A one dimensional array, with values either 0 (most entries) or >0.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    self: this instance of the fitted model. This can be anything, as long as it is compatible\n",
        "        with your prediction methods.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: train your model here.\n",
        "    # Don't forget any preprocessing of the raw data here\n",
        "    \n",
        "    #linear regression\n",
        "    from sklearn.linear_model import LinearRegression \n",
        "\n",
        "    #X = pd.get_dummies(X_raw[['pol_coverage','drv_age1']])\n",
        "    X_raw[['vh_age','vh_speed','vh_value','vh_weight']] = X_raw[['vh_age','vh_speed','vh_value','vh_weight']].fillna(X_raw[['vh_age','vh_speed','vh_value','vh_weight']].mean())\n",
        "    X = pd.get_dummies(X_raw.drop(columns=['id_policy','vh_make_model','drv_age1','drv_age_lic1','drv_age2','drv_age_lic2']))\n",
        "    X['drv_age_min']=X_raw[['drv_age1','drv_age2']].min(axis=1)\n",
        "    X['drv_age_lic_min']=X_raw[['drv_age_lic1','drv_age_lic2']].min(axis=1)\n",
        "    #X['drv_age_max']=X_raw[['drv_age1','drv_age2']].max(axis=1)\n",
        "    #X['drv_age_lic_max']=X_raw[['drv_age_lic1','drv_age_lic2']].max(axis=1)\n",
        "    #X['drv_age_diff']=X['drv_age_max'] - X['drv_age_min']\n",
        "    X['drv_age_diff']=X_raw[['drv_age1','drv_age2']].max(axis=1) - X['drv_age_min']\n",
        "    #X['drv_age_lic_diff']=X['drv_age_lic_max'] - X['drv_age_lic_min']\n",
        "    X['one_driver'] = (X_raw['drv_age2'].isnull())*1.0\n",
        "    #X['vh_value_to_weight'] = X_raw['vh_value']/X_raw['vh_weight']\n",
        "    \n",
        "    #function to compute vh_value_to_weight taking into account 0 weight\n",
        "    #X['vh_value_to_weight'] = X_raw.apply(lambda x: vh_value_to_weight(x), axis = 1)\n",
        "\n",
        "\n",
        "    reg = LinearRegression().fit(X, y_raw)\n",
        "\n",
        "    #h2o gbm\n",
        "    #import h2o\n",
        "    #from h2o.estimators import H2OGradientBoostingEstimator\n",
        "    \n",
        "    #cat_columns = ['pol_coverage','pol_pay_freq','pol_payd','pol_usage','drv_sex1','drv_sex2','vh_fuel','vh_type']\n",
        "    #col_types = dict(zip(cat_columns, ['enum']*len(cat_columns)))\n",
        "\n",
        "    #train_data_h2o = h2o.H2OFrame(X_raw.merge(y_raw.to_frame(), left_index=True, right_index=True),column_types = col_types)\n",
        "\n",
        "    #model_h2o = H2OGradientBoostingEstimator(ntrees = 500, max_depth=4, stopping_metric = 'rmse')\n",
        "    #predictors = list(X_raw.drop(['id_policy', 'year', 'vh_make_model'], axis=1).columns)\n",
        "\n",
        "    #model_h2o.train(x=predictors,y='claim_amount',training_frame = train_data_h2o)\n",
        "    \n",
        "    import xgboost as xgb\n",
        "    #X = pd.get_dummies(X_raw.drop(columns=['id_policy','vh_make_model']))\n",
        "\n",
        "    #model_xgb = xgb.XGBRegressor(\n",
        "    #    n_estimators=100,\n",
        "    #    reg_lambda=1,\n",
        "    #    gamma=0,\n",
        "    #    max_depth=2\n",
        "    #    )\n",
        "    \n",
        "    #model_xgb.fit(X, y_raw)\n",
        "    \n",
        "    #model_gbm = GradientBoostingRegressor(random_state=0, max_depth = 2)\n",
        "    #model_gbm = GradientBoostingRegressor(random_state=0, n_estimators = 500, subsample = 0.9, max_depth = 4)\n",
        "    #model_gbm.fit(X, y_raw)\n",
        "\n",
        "    #model_rf = RandomForestRegressor(random_state=0)\n",
        "    #model_rf.fit(X, y_raw)\n",
        "\n",
        "    #model_ada = AdaBoostRegressor(random_state = 0)\n",
        "    #model_ada.fit(X, y_raw)\n",
        "\n",
        "    #model_hist = HistGradientBoostingRegressor(random_state = 0)\n",
        "    #model_hist.fit(X, y_raw)\n",
        "\n",
        "    both_data = X.merge(y_raw.to_frame(), left_index=True, right_index=True)\n",
        "    both_data_sev = both_data[both_data['claim_amount']>0]\n",
        "\n",
        "    both_data_max = both_data[both_data['pol_coverage_Max'] == 1]\n",
        "    both_data_sev_max = both_data_sev[both_data_sev['pol_coverage_Max'] == 1]\n",
        "\n",
        "    both_data_notmax = both_data[both_data['pol_coverage_Max'] == 0]\n",
        "    both_data_sev_notmax = both_data_sev[both_data_sev['pol_coverage_Max'] == 0]\n",
        "\n",
        "    model_gbm_sev = GradientBoostingRegressor(random_state=0, max_depth = 2, n_estimators = 30)\n",
        "    #model_gbm = GradientBoostingRegressor(random_state=0, n_estimators = 500, subsample = 0.9, max_depth = 4)\n",
        "    model_gbm_sev.fit(both_data_sev.drop(['claim_amount'],axis=1), both_data_sev['claim_amount'])\n",
        "\n",
        "    model_gbm_sev_max = GradientBoostingRegressor(random_state=0, max_depth = 2, n_estimators = 25)\n",
        "    #model_gbm = GradientBoostingRegressor(random_state=0, n_estimators = 500, subsample = 0.9, max_depth = 4)\n",
        "    model_gbm_sev_max.fit(both_data_sev_max.drop(['claim_amount'],axis=1), both_data_sev_max['claim_amount'])\n",
        "    \n",
        "    model_gbm_sev_notmax = GradientBoostingRegressor(random_state=0, max_depth = 2, n_estimators = 15)\n",
        "    #model_gbm = GradientBoostingRegressor(random_state=0, n_estimators = 500, subsample = 0.9, max_depth = 4)\n",
        "    model_gbm_sev_notmax.fit(both_data_sev_notmax.drop(['claim_amount'],axis=1), both_data_sev_notmax['claim_amount'])\n",
        "\n",
        "    model_gbm_freq = GradientBoostingClassifier(random_state=0, max_depth = 3, n_estimators = 120)\n",
        "    #model_gbm = GradientBoostingRegressor(random_state=0, n_estimators = 500, subsample = 0.9, max_depth = 4)\n",
        "    model_gbm_freq.fit(both_data.drop(['claim_amount'],axis=1), (both_data['claim_amount']>0)*1)\n",
        "\n",
        "    model_gbm_freq_max = GradientBoostingClassifier(random_state=0, max_depth = 3, n_estimators = 100)\n",
        "    #model_gbm = GradientBoostingRegressor(random_state=0, n_estimators = 500, subsample = 0.9, max_depth = 4)\n",
        "    model_gbm_freq_max.fit(both_data_max.drop(['claim_amount'],axis=1), (both_data_max['claim_amount']>0)*1)\n",
        "\n",
        "    model_gbm_freq_notmax = GradientBoostingClassifier(random_state=0, max_depth = 3, n_estimators = 50)\n",
        "    #model_gbm = GradientBoostingRegressor(random_state=0, n_estimators = 500, subsample = 0.9, max_depth = 4)\n",
        "    model_gbm_freq_notmax.fit(both_data_notmax.drop(['claim_amount'],axis=1), (both_data_notmax['claim_amount']>0)*1)\n",
        "\n",
        "    return [model_gbm_freq, model_gbm_sev,model_gbm_freq_max, model_gbm_sev_max,model_gbm_freq_notmax, model_gbm_sev_notmax]#[model_gbm_freq, model_gbm_sev]#model_h2o#[model_gbm_freq, model_gbm_sev]#[model_gbm, reg, both_data] #[model_gbm, reg, model_hist] #[model_hist, model_hist, model_hist] #[model_gbm, reg, model_rf]#[model_gbm, reg, model_xgb] #[model_gbm, reg] #reg #model_gbm #reg #model_xgb #model_h2o #reg #np.mean(y_raw)  # By default, training a model that returns a mean value (a mean model)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfjGFHcXd9Yh"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wtCLn_Xd9Yi"
      },
      "source": [
        "trained_model = fit_model(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgRJWfmm3VL1",
        "outputId": "21e9d642-8b3f-4dbd-eea3-97a8eb669e80"
      },
      "source": [
        "(trained_model[2]).columns\r\n",
        "((trained_model[2]['claim_amount']>0)*1.0).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23292.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjUk7tfjd9Yi"
      },
      "source": [
        "**Important note**: your training code should be able to run in under 10 minutes (since this notebook is re-run entirely on the server side). \n",
        "\n",
        "If you run into an issue here we recommend using the *zip file submission* (see the [challenge page](https://www.aicrowd.com/challenges/insurance-pricing-game/#how-to%20submit)). In short, you can simply do this by copy-pasting your `fit_model`, `predict_expected_claim` and `predict_premium` functions to the `model.py` file.\n",
        "\n",
        "Note that if you want to perform extensive cross-validation/hyper-parameter selection, it is better to do them offline, in a separate notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWYcr_Ued9Yi"
      },
      "source": [
        "## Saving your model\n",
        "\n",
        "You can save your model to a file here, so you don't need to retrain it every time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6iWwkmHd9Yi"
      },
      "source": [
        "def save_model(model_path):\n",
        "  with open(model_path, 'wb') as target_file:\n",
        "      pickle.dump(trained_model, target_file)\n",
        "\n",
        "#def save_model(model_path):\n",
        "#  model_path_2 = h2o.save_model(model=trained_model, path=model_path, force=True)\n",
        "#  return model_path_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwEEP95EMow4"
      },
      "source": [
        "save_model(Config.MODEL_OUTPUT_PATH)\r\n",
        "#print(Config.MODEL_OUTPUT_PATH)\r\n",
        "#model_path_2 = h2o.save_model(model=trained_model, path=Config.MODEL_OUTPUT_PATH, force=True)\r\n",
        "#s = save_model(Config.MODEL_OUTPUT_PATH)\r\n",
        "#print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml0kp82r_SsW"
      },
      "source": [
        "#class Config:\r\n",
        "#  TRAINING_DATA_PATH = 'training.csv'\r\n",
        "#  #MODEL_OUTPUT_PATH = 'model.pkl'\r\n",
        "#  MODEL_OUTPUT_PATH = s\r\n",
        "#  AICROWD_API_KEY = '0b70146b9714e6c7f3393b86c15e9c4d'  # You can get the key from https://aicrowd.com/participants/me\r\n",
        "#  ADDITIONAL_PACKAGES = [\r\n",
        "#    'numpy',  # you can define versions as well, numpy==0.19.2\r\n",
        "#    'pandas',\r\n",
        "#    'scikit-learn==' + sklearn.__version__,\r\n",
        "#    'h2o'\r\n",
        "#  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G3KPnlsd9Yi"
      },
      "source": [
        "If you need to load it from file, you can use this code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICY88PT5d9Yi"
      },
      "source": [
        "def load_model(model_path):\n",
        "  with open(model_path, 'rb') as target:\n",
        "      return pickle.load(target)\n",
        "\n",
        "#def load_model(model_path):\n",
        "#  saved_model = h2o.load_model(model_path)\n",
        "#  return saved_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxTX1TYOMsWK"
      },
      "source": [
        "trained_model = load_model(Config.MODEL_OUTPUT_PATH)\r\n",
        "#trained_model = load_model(s)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1md65LzDDVp",
        "outputId": "7be0dca8-9787-4fd7-b1f8-b17f45a0348c"
      },
      "source": [
        "#print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/model/GBM_model_python_1608744081390_4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVeJiR1Ud9Yi"
      },
      "source": [
        "# Predicting the claims üíµ\n",
        "\n",
        "The second function, `predict_expected_claim`, takes your trained model and a dataframe of contracts, and outputs a prediction for the (expected) claim incurred by each contract. This expected claim can be seen as the probability of an accident multiplied by the cost of that accident.\n",
        "\n",
        "This is the function used to compute the _RMSE_ leaderboard, where the model best able to predict claims wins."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgM1xNf0d9Yi"
      },
      "source": [
        "def predict_expected_claim(model, X_raw):\n",
        "    \"\"\"Model prediction function: predicts the expected claim based on the pricing model.\n",
        "\n",
        "    This functions estimates the expected claim made by a contract (typically, as the product\n",
        "    of the probability of having a claim multiplied by the expected cost of a claim if it occurs),\n",
        "    for each contract in the dataset X_raw.\n",
        "\n",
        "    This is the function used in the RMSE leaderboard, and hence the output should be as close\n",
        "    as possible to the expected cost of a contract.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: a Python object that describes your model. This can be anything, as long\n",
        "        as it is consistent with what `fit` outpurs.\n",
        "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
        "        Each row is a different contract. This data has not been processed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    avg_claims: a one-dimensional Numpy array of the same length as X_raw, with one\n",
        "        expected claim per contract (in same order). These expected claims must be POSITIVE (>0).\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: estimate the expected claim of every contract.\n",
        "    # Don't forget any preprocessing of the raw data here\n",
        "    \n",
        "    #linear regression\n",
        "    #X = pd.get_dummies(X_raw[['pol_coverage','drv_age1']])\n",
        "    X_raw[['vh_age','vh_speed','vh_value','vh_weight']] = X_raw[['vh_age','vh_speed','vh_value','vh_weight']].fillna(X_raw[['vh_age','vh_speed','vh_value','vh_weight']].mean())\n",
        "    X = pd.get_dummies(X_raw.drop(columns=['id_policy','vh_make_model','drv_age1','drv_age_lic1','drv_age2','drv_age_lic2']))\n",
        "    X['drv_age_min']=X_raw[['drv_age1','drv_age2']].min(axis=1)\n",
        "    X['drv_age_lic_min']=X_raw[['drv_age_lic1','drv_age_lic2']].min(axis=1)\n",
        "    #X['drv_age_max']=X_raw[['drv_age1','drv_age2']].max(axis=1)\n",
        "    #X['drv_age_lic_max']=X_raw[['drv_age_lic1','drv_age_lic2']].max(axis=1)\n",
        "    #X['drv_age_diff']=X['drv_age_max'] - X['drv_age_min']\n",
        "    X['drv_age_diff']=X_raw[['drv_age1','drv_age2']].max(axis=1) - X['drv_age_min']\n",
        "    #X['drv_age_lic_diff']=X['drv_age_lic_max'] - X['drv_age_lic_min']\n",
        "    X['one_driver'] = (X_raw['drv_age2'].isnull())*1.0\n",
        "    #X['vh_value_to_weight'] = X_raw['vh_value']/X_raw['vh_weight']\n",
        "    #X['vh_value_to_weight'] = X_raw.apply(lambda x: vh_value_to_weight(x), axis = 1)\n",
        "\n",
        "    #h2o\n",
        "    #cat_columns = ['pol_coverage','pol_pay_freq','pol_payd','pol_usage','drv_sex1','drv_sex2','vh_fuel','vh_type']\n",
        "    #col_types = dict(zip(cat_columns, ['enum']*len(cat_columns)))\n",
        "\n",
        "    #X = h2o.H2OFrame(X_raw,column_types = col_types)\n",
        "    \n",
        "    #xgb\n",
        "    import xgboost as xgb\n",
        "    #X = pd.get_dummies(X_raw.drop(columns=['id_policy','vh_make_model']))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #return ((model[0]).predict(X) + (model[1]).predict(X) + (model[2]).predict(X))/3 #0.5*((model[0]).predict(X) + (model[1]).predict(X)) #model.predict(X) #np.full( (len(X_raw.index),), model )  # Estimate that each contract will cost 114 (this is the naive mean model). You should change this!\n",
        "    #return 0.5*((model[0]).predict(X) + (model[1]).predict(X))\n",
        "    return [c[1] for c in (model[0]).predict_proba(X)] * (model[1]).predict(X)\n",
        "    #return X\n",
        "    #if (X['pol_coverage_Max'] == 1):\n",
        "    #  return [c[1] for c in (model[2]).predict_proba(X)] * (model[3]).predict(X)\n",
        "    #else:\n",
        "    #  return [c[1] for c in (model[4]).predict_proba(X)] * (model[5]).predict(X)\n",
        "    \n",
        "    #return (X['pol_coverage_Max'] == 1) * [c[1] for c in (model[2]).predict_proba(X)] * (model[3]).predict(X) + (X['pol_coverage_Max'] == 0)*[c[1] for c in (model[4]).predict_proba(X)] * (model[5]).predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN7RqHcld9Yi"
      },
      "source": [
        "To test your function, run it on your training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWMRuOxi9V_j",
        "outputId": "f454021c-5b42-414c-9d10-fbd3b3bae731"
      },
      "source": [
        "X_train[['vh_age','vh_speed','vh_value','vh_weight']] = X_train[['vh_age','vh_speed','vh_value','vh_weight']].fillna(X_train[['vh_age','vh_speed','vh_value','vh_weight']].mean())\r\n",
        "X = pd.get_dummies(X_train.drop(columns=['id_policy','vh_make_model','drv_age1','drv_age_lic1','drv_age2','drv_age_lic2']))\r\n",
        "X['drv_age_min']=X_train[['drv_age1','drv_age2']].min(axis=1)\r\n",
        "X['drv_age_lic_min']=X_train[['drv_age_lic1','drv_age_lic2']].min(axis=1)\r\n",
        "X['one_driver'] = (X_train['drv_age2'].isnull())*1.0\r\n",
        "print(trained_model[0].predict(X).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Pu1UE-d9Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a028e47-34c7-449a-b9f9-1da08f25e34e"
      },
      "source": [
        "predict_expected_claim(trained_model, X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([126.65886694,  84.65301511, 105.20172993, ..., 117.7890563 ,\n",
              "        62.90082219, 144.34193765])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LuitAiQd9Yi"
      },
      "source": [
        "# Pricing contracts üí∞üí∞\n",
        "\n",
        "The third and final function, `predict_premium`, takes your trained model and a dataframe of contracts, and outputs a _price_ for each of these contracts. **You are free to set this prices however you want!** These prices will then be used in competition with other models: contracts will choose the model offering the lowest price, and this model will have to pay the cost if an accident occurs.\n",
        "\n",
        "This is the function used to compute the _profit_ leaderboard: your model will participate in many markets of size 10, populated by other participants' model, and we compute the average profit of your model over all the markets it participated in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agmv13hnd9Yi"
      },
      "source": [
        "def predict_premium(model, X_raw):\n",
        "    \"\"\"Model prediction function: predicts premiums based on the pricing model.\n",
        "\n",
        "    This function outputs the prices that will be offered to the contracts in X_raw.\n",
        "    premium will typically depend on the average claim predicted in \n",
        "    predict_average_claim, and will add some pricing strategy on top.\n",
        "\n",
        "    This is the function used in the average profit leaderboard. Prices output here will\n",
        "    be used in competition with other models, so feel free to use a pricing strategy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: a Python object that describes your model. This can be anything, as long\n",
        "        as it is consistent with what `fit` outpurs.\n",
        "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
        "        Each row is a different contract. This data has not been processed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    prices: a one-dimensional Numpy array of the same length as X_raw, with one\n",
        "        price per contract (in same order). These prices must be POSITIVE (>0).\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: return a price for everyone.\n",
        "    # Don't forget any preprocessing of the raw data here\n",
        "\n",
        "    return predict_expected_claim(model, X_raw)*1.05  # Default: price at the pure premium with no pricing strategy."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu7T3lQ_d9Yi"
      },
      "source": [
        "To test your function, run it on your training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Ej-1zcd9Yi"
      },
      "source": [
        "prices = predict_premium(trained_model, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcU5hWPHd9Yi"
      },
      "source": [
        "#### Profit on training data\n",
        "\n",
        "In order for your model to be considered in the profit competition, it needs to make nonnegative profit over its training set. You can check that your model satisfies this condition below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf389fhYd9Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36062d73-811a-4626-b0ee-7613c2a8c691"
      },
      "source": [
        "print('Premium offered:', prices.mean())\n",
        "print('Premium offered min:', prices.min())\n",
        "print('Premium offered max:', prices.max())\n",
        "print('Income:', prices.sum())\n",
        "print('Losses:', y_train.sum())\n",
        "\n",
        "if prices.sum() < y_train.sum():\n",
        "    print('Your model loses money on the training data! It does not satisfy market rule 1: Non-negative training profit.')\n",
        "    print('This model will be disqualified from the weekly profit leaderboard, but can be submitted for educational purposes to the RMSE leaderboard.')\n",
        "else:\n",
        "    print('Your model passes the non-negative training profit test!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Premium offered: 119.87324173993659\n",
            "Premium offered min: 6.168047882032584\n",
            "Premium offered max: 920.2660005203054\n",
            "Income: 27356991.73692137\n",
            "Losses: 26057988.080000006\n",
            "Your model passes the non-negative training profit test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQlsVqDqd9Yi"
      },
      "source": [
        "# Ready? Submit to AIcrowd üöÄ\n",
        "\n",
        "If you are satisfied with your code, run the code below to send your code to the AICrowd servers for evaluation! This requires the variable `trained_model` to be defined by your previous code.\n",
        "\n",
        "**Make sure you have included all packages needed to run your code in the [_\"Packages\"_](#packages) section.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovm0PyTEd9Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29102028-cd2c-4ab5-e3c3-a1b906d7f6c0"
      },
      "source": [
        "%aicrowd_submit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "üöÄ Preparing to submit...\n",
            "‚öôÔ∏è Collecting the submission code...\n",
            "üíæ Preparing the submission zip file...\n",
            "adding: requirements.txt (stored 0%)\n",
            "adding: config.json (deflated 8%)\n",
            "adding: predict.py (deflated 52%)\n",
            "adding: predict_premium.py (deflated 53%)\n",
            "adding: utils.py (deflated 33%)\n",
            "adding: model.pkl (deflated 65%)\n",
            "adding: fit_model.py (deflated 75%)\n",
            "adding: global_imports.py (deflated 60%)\n",
            "adding: predict_expected_claim.py (deflated 63%)\n",
            "adding: load_model.py (deflated 29%)\n",
            "adding: save_model.py (deflated 33%)\n",
            "Verifying API Key...\n",
            "API Key valid\n",
            "Saved API Key successfully!\n",
            "‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
            "‚îÇ                                           Successfully submitted!                                            ‚îÇ\n",
            "‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n",
            "Important links\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ  This submission ‚îÇ https://www.aicrowd.com/challenges/insurance-pricing-game/submissions/111334              ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                                           ‚îÇ\n",
            "‚îÇ  All submissions ‚îÇ https://www.aicrowd.com/challenges/insurance-pricing-game/submissions?my_submissions=true ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                                           ‚îÇ\n",
            "‚îÇ      Leaderboard ‚îÇ https://www.aicrowd.com/challenges/insurance-pricing-game/leaderboards                    ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                                           ‚îÇ\n",
            "‚îÇ Discussion forum ‚îÇ https://discourse.aicrowd.com/c/insurance-pricing-game                                    ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                                           ‚îÇ\n",
            "‚îÇ   Challenge page ‚îÇ https://www.aicrowd.com/challenges/insurance-pricing-game                                 ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}